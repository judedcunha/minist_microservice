{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebfb9edc-762d-48ee-bd1c-e43632463a8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.19.0)\n",
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.10/site-packages (1.79.0)\n",
      "Requirement already satisfied: kfp in /opt/conda/lib/python3.10/site-packages (2.5.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.38.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.26.0)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.14.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.25.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.14.0)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.0.7)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.10.6)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Requirement already satisfied: click<9,>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from kfp) (8.1.8)\n",
      "Requirement already satisfied: kfp-pipeline-spec==0.2.2 in /opt/conda/lib/python3.10/site-packages (from kfp) (0.2.2)\n",
      "Requirement already satisfied: kfp-server-api<2.1.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from kfp) (2.0.5)\n",
      "Requirement already satisfied: kubernetes<27,>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from kfp) (26.1.0)\n",
      "Requirement already satisfied: PyYAML<7,>=5.3 in /opt/conda/lib/python3.10/site-packages (from kfp) (6.0.2)\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from kfp) (0.10.1)\n",
      "Requirement already satisfied: tabulate<1,>=0.8.6 in /opt/conda/lib/python3.10/site-packages (from kfp) (0.9.0)\n",
      "Requirement already satisfied: urllib3<2.0.0 in /opt/conda/lib/python3.10/site-packages (from kfp) (1.26.20)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.67.0rc1)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.49.0rc1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.14.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.6.0)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from kfp-server-api<2.1.0,>=2.0.0->kfp) (2024.12.14)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes<27,>=8.0.0->kfp) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from kubernetes<27,>=8.0.0->kfp) (2.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (2.27.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib->kubernetes<27,>=8.0.0->kfp) (3.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (2.14.0)\n",
      "Requirement already satisfied: explainable_ai_sdk in /opt/conda/lib/python3.10/site-packages (1.3.3)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement PIL (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for PIL\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow google-cloud-aiplatform kfp\n",
    "! pip install google-cloud-storage explainable_ai_sdk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39cdc6be-4ebc-46f2-b255-6d3afb61e4d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(\n",
    "    project=\"minist-microservice\",\n",
    "    location=\"us-central1\",\n",
    "    staging_bucket=\"gs://mnist_model_bucket\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8bf70fa-2cee-4422-9b0f-b5aeb75797bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 22:32:27.231887: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742164347.260343   17427 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742164347.268516   17427 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742164347.291128   17427 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742164347.291174   17427 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742164347.291177   17427 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742164347.291180   17427 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-16 22:32:27.297727: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Filter only digits 3 and 7\n",
    "train_filter = (y_train == 3) | (y_train == 7)\n",
    "test_filter = (y_test == 3) | (y_test == 7)\n",
    "\n",
    "x_train, y_train = x_train[train_filter], y_train[train_filter]\n",
    "x_test, y_test = x_test[test_filter], y_test[test_filter]\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Reshape data for CNN input (28x28 images with 1 channel)\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Convert labels to binary (3 → 0, 7 → 1)\n",
    "y_train = (y_train == 7).astype(int)\n",
    "y_test = (y_test == 7).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5aa68b6-3c76-4f14-b9a0-079097ecbb41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-03-16 22:32:30.766542: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93682d50-8cc9-4976-8cc8-a408dddd56ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9641 - loss: 0.1021 - val_accuracy: 0.9931 - val_loss: 0.0148\n",
      "Epoch 2/10\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9962 - loss: 0.0127 - val_accuracy: 0.9946 - val_loss: 0.0179\n",
      "Epoch 3/10\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9976 - loss: 0.0099 - val_accuracy: 0.9971 - val_loss: 0.0058\n",
      "Epoch 4/10\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9982 - loss: 0.0068 - val_accuracy: 0.9975 - val_loss: 0.0069\n",
      "Epoch 5/10\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9977 - loss: 0.0095 - val_accuracy: 0.9990 - val_loss: 0.0046\n",
      "Epoch 6/10\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9982 - loss: 0.0049 - val_accuracy: 0.9971 - val_loss: 0.0089\n",
      "Epoch 7/10\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9988 - loss: 0.0033 - val_accuracy: 0.9990 - val_loss: 0.0037\n",
      "Epoch 8/10\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9998 - loss: 6.9478e-04 - val_accuracy: 0.9995 - val_loss: 0.0020\n",
      "Epoch 9/10\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9999 - loss: 2.1571e-04 - val_accuracy: 0.9975 - val_loss: 0.0091\n",
      "Epoch 10/10\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9985 - loss: 0.0043 - val_accuracy: 0.9941 - val_loss: 0.0194\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7071d9f-7e07-4999-ac81-99c3c33fc581",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9912 - loss: 0.0296\n",
      "Test Accuracy: 0.9941\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a131c03d-c7ae-43ed-a66d-9777c36adf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Confusion Matrix:\n",
      "[[1010    0]\n",
      " [  12 1016]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "y_pred = (model.predict(x_test) > 0.5).astype(int)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "656b512c-9091-4c77-9141-efd7bb8aeb29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_cnn_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_cnn_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'mnist_cnn_model'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  140495408188752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140495408193680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140495408198784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140495408199488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140495408201424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140495408199664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140495408201248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140495408402976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "model.save(\"mnist_cnn_model.keras\")\n",
    "# Export the model in SavedModel format\n",
    "model.export(\"mnist_cnn_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18e800cb-65ce-421b-a605-0fe08e13a256",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_cnn_model_with_metadata/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_cnn_model_with_metadata/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mnist_cnn_model_with_metadata'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import explainable_ai_sdk\n",
    "from explainable_ai_sdk.metadata.tf.v2 import SavedModelMetadataBuilder\n",
    "\n",
    "# Point to your SavedModel directory\n",
    "LOCAL_PATH_TO_MODEL = \"mnist_cnn_model\"  \n",
    "\n",
    "# Initialize metadata builder\n",
    "metadata_builder = SavedModelMetadataBuilder(LOCAL_PATH_TO_MODEL)\n",
    "\n",
    "# Save the model with metadata\n",
    "LOCAL_PATH_TO_SAVED_MODEL_ARTIFACT = \"mnist_cnn_model_with_metadata\"\n",
    "metadata_builder.save_model_with_metadata(LOCAL_PATH_TO_SAVED_MODEL_ARTIFACT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7e48cb-097a-4b36-8cfa-d0e68bcc5f40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'explainable_ai_sdk' has no attribute 'IntegratedGradientsConfig'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexplainable_ai_sdk\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the model with Integrated Gradients configuration\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model_with_metadata \u001b[38;5;241m=\u001b[39m explainable_ai_sdk\u001b[38;5;241m.\u001b[39mload_model_from_local_path(\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmnist_cnn_model_with_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m----> 6\u001b[0m     config\u001b[38;5;241m=\u001b[39m\u001b[43mexplainable_ai_sdk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIntegratedGradientsConfig\u001b[49m(\n\u001b[1;32m      7\u001b[0m         steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,  \u001b[38;5;66;03m# Increase steps for smoother attributions (slower)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'explainable_ai_sdk' has no attribute 'IntegratedGradientsConfig'"
     ]
    }
   ],
   "source": [
    "import explainable_ai_sdk\n",
    "\n",
    "# Load the model with Integrated Gradients configuration\n",
    "model_with_metadata = explainable_ai_sdk.load_model_from_local_path(\n",
    "    \"mnist_cnn_model_with_metadata\",\n",
    "    config=explainable_ai_sdk.IntegratedGradientsConfig(\n",
    "        steps=50,  # Increase steps for smoother attributions (slower)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e477a2c-8b94-4840-b9ae-057f5f932e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00525b46-08ae-48e1-a609-ff4b59430387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7936237-9b50-46b3-bfb2-036f654043bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py:660: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: keras_tensor\n",
      "Received: inputs=['Tensor(shape=(None, 28, 28, 1))']\n",
      "  warnings.warn(msg)\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py:660: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gs://mnist_model_bucket/mnist_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gs://mnist_model_bucket/mnist_model/assets\n"
     ]
    }
   ],
   "source": [
    "# 1. Define preprocessing\n",
    "def _preprocess(bytes_input):\n",
    "    decoded = tf.io.decode_png(bytes_input, channels=1)\n",
    "    decoded = tf.image.convert_image_dtype(decoded, tf.float32)\n",
    "    resized = tf.image.resize(decoded, size=(28, 28))\n",
    "    return resized\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec([None], tf.string)])\n",
    "def preprocess_fn(bytes_inputs):\n",
    "    with tf.device(\"cpu:0\"):\n",
    "        decoded_images = tf.map_fn(_preprocess, bytes_inputs, dtype=tf.float32)\n",
    "    return {\"input_1\": decoded_images}  # Key matches input layer name\n",
    "\n",
    "# 2. Define serving function with correct input name\n",
    "m_call = tf.function(model.call).get_concrete_function(\n",
    "    [tf.TensorSpec(shape=[None, 28, 28, 1], dtype=tf.float32, name=\"input_1\")]\n",
    ")\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec([None], tf.string)])\n",
    "def serving_fn(bytes_inputs):\n",
    "    images = preprocess_fn(bytes_inputs)\n",
    "    prob = m_call(**images)  # Pass keyword args\n",
    "    return prob\n",
    "\n",
    "# Export to SavedModel\n",
    "export_path = 'gs://mnist_model_bucket/mnist_model'\n",
    "# 3. Export the model\n",
    "tf.saved_model.save(\n",
    "    model,\n",
    "    export_path,\n",
    "    signatures={\n",
    "        'serving_default': serving_fn,\n",
    "        'xai_preprocess': preprocess_fn,\n",
    "        'xai_model': m_call\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f6597e2-196e-4dc4-b9c4-f5637cc75507",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from explainable_ai_sdk.metadata.tf.v2 import SavedModelMetadataBuilder\n",
    "\n",
    "# Initialize metadata builder\n",
    "builder = SavedModelMetadataBuilder(export_path, signature_name='xai_model')\n",
    "\n",
    "# Use a black baseline (all zeros for MNIST)\n",
    "baseline = np.zeros((28, 28, 1)).tolist()  # Grayscale baseline\n",
    "builder.set_image_metadata(\n",
    "    input_name='input_1',  # Match model input layer name\n",
    "    input_baselines=[baseline]\n",
    ")\n",
    "builder.save_metadata(export_path)  # Save metadata to the same GCS path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d609d02-7eb3-4c1b-89b0-2ce1bb4cee8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
      "\u001b[1;31mERROR:\u001b[0m (gcloud.ai-platform.models.create) Resource in projects [minist-microservice] is the subject of a conflict: Field: model.name Error: A model with the same name already exists.\n",
      "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
      "  fieldViolations:\n",
      "  - description: A model with the same name already exists.\n",
      "    field: model.name\n",
      "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
      "Explanations reflect patterns in your model, but don't necessarily reveal fundamental relationships about your data population. See https://cloud.google.com/vertex-ai/docs/explainable-ai/limitations for more information.\n",
      "\u001b[1;31mERROR:\u001b[0m (gcloud.beta.ai-platform.versions.create) RESOURCE_EXHAUSTED: The requested number of n1-standard-4 exceeds the quota limit. Current usage/limit: 0/0, Requested: 8.\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "MODEL_NAME = \"mnist_model\"\n",
    "!gcloud ai-platform models create {MODEL_NAME} --region=us-central1\n",
    "\n",
    "# Deploy with Integrated Gradients\n",
    "VERSION_NAME=\"v1\"\n",
    "! gcloud beta ai-platform versions create $VERSION_NAME \\\n",
    "  --model=$MODEL_NAME \\\n",
    "  --region=us-central1 \\\n",
    "  --framework=TENSORFLOW \\\n",
    "  --runtime-version=2.8 \\\n",
    "  --origin=$export_path \\\n",
    "  --machine-type=n1-standard-4 \\\n",
    "  --explanation-method=integrated-gradients \\\n",
    "  --num-integral-steps=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f815ee9-b118-4c7a-9848-1419d70e75ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "# Convert MNIST test image to base64\n",
    "test_image = x_test[0].reshape(28, 28, 1) * 255  # Reshape and scale to [0, 255]\n",
    "test_image = np.squeeze(test_image)  # Remove the extra dimension (28, 28, 1) → (28, 28)\n",
    "test_image_pil = Image.fromarray(test_image.astype('uint8'), mode='L')\n",
    "buffer = io.BytesIO()\n",
    "test_image_pil.save(buffer, format=\"PNG\")\n",
    "b64_image = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "\n",
    "# Format instance\n",
    "instances = [{\"bytes_inputs\": {\"b64\": b64_image}}]  # Match serving_fn input name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce5edf96-12be-408f-b325-5880fe2304f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID=\"minist-microservice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7eb13670-26f8-4442-a2cb-0385a8badf43",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target URI https://ml.googleapis.com/v1/projects/minist-microservice/models/mnist_model returns HTTP 404 error.\nPlease check if the project, model, and version names are given correctly.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexplainable_ai_sdk\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model_from_ai_platform\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load deployed model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m remote_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model_from_ai_platform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPROJECT_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Get explanations\u001b[39;00m\n\u001b[1;32m     10\u001b[0m explanations \u001b[38;5;241m=\u001b[39m remote_model\u001b[38;5;241m.\u001b[39mexplain(instances)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/explainable_ai_sdk/model/model_factory.py:73\u001b[0m, in \u001b[0;36mload_model_from_ai_platform\u001b[0;34m(project, model, version, credentials, region, input_modalities)\u001b[0m\n\u001b[1;32m     70\u001b[0m model_endpoint_uri \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mget_endpoint_uri(resouce_path, region, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m input_modalities:\n\u001b[1;32m     72\u001b[0m   input_modalities \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mcreate_modality_inputs_map_from_metadata(\n\u001b[0;32m---> 73\u001b[0m       \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_explanation_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_endpoint_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _MODEL_REGISTRY[_CAIP_MODEL_KEY](model_endpoint_uri, credentials,\n\u001b[1;32m     76\u001b[0m                                         input_modalities)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/explainable_ai_sdk/model/utils.py:93\u001b[0m, in \u001b[0;36mfetch_explanation_metadata\u001b[0;34m(model_endpoint_uri, credentials)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfetch_explanation_metadata\u001b[39m(\n\u001b[1;32m     77\u001b[0m     model_endpoint_uri: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     78\u001b[0m     credentials: Optional[google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mcredentials\u001b[38;5;241m.\u001b[39mCredentials] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     79\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m explain_metadata\u001b[38;5;241m.\u001b[39mExplainMetadata:\n\u001b[1;32m     80\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Fetches explanation metadata from user's deployment uri.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m  This method will call the AIP service first to get deployment uri,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m     Model's explanation metatdata.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m     92\u001b[0m   explanation_md_uri \u001b[38;5;241m=\u001b[39m _extract_explanation_metadata_uri(\n\u001b[0;32m---> 93\u001b[0m       \u001b[43m_get_deployment_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_endpoint_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     95\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m explain_metadata\u001b[38;5;241m.\u001b[39mExplainMetadata\u001b[38;5;241m.\u001b[39mfrom_file(explanation_md_uri)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/explainable_ai_sdk/model/utils.py:48\u001b[0m, in \u001b[0;36m_get_deployment_uri\u001b[0;34m(model_endpoint_uri, credentials)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_deployment_uri\u001b[39m(\n\u001b[1;32m     33\u001b[0m     model_endpoint_uri: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     34\u001b[0m     credentials: Optional[google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mcredentials\u001b[38;5;241m.\u001b[39mCredentials] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     35\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Gets the deployment uri of the model from AIP.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m      missing from the returned version information.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[43mhttp_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_get_request_to_ai_platform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_endpoint_uri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeploymentUri\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThere is no deploymentUri information in this version\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/explainable_ai_sdk/model/http_utils.py:96\u001b[0m, in \u001b[0;36mmake_get_request_to_ai_platform\u001b[0;34m(uri, credentials, timeout_ms)\u001b[0m\n\u001b[1;32m     93\u001b[0m headers \u001b[38;5;241m=\u001b[39m _get_request_header(credentials)\n\u001b[1;32m     95\u001b[0m r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(uri, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39mtimeout_ms)\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_handle_ai_platform_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/explainable_ai_sdk/model/http_utils.py:70\u001b[0m, in \u001b[0;36m_handle_ai_platform_response\u001b[0;34m(uri, response)\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m:\n\u001b[0;32m---> 70\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTarget URI \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m returns HTTP 404 error.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     71\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease check if the project, model, and version names \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     72\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mare given correctly.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     73\u001b[0m                     )\u001b[38;5;241m.\u001b[39mformat(uri))\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTarget URI \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m returns HTTP \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m error.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     75\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease check the raw error message: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     76\u001b[0m                   )\u001b[38;5;241m.\u001b[39mformat(uri, response\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m.\u001b[39mtext))\n",
      "\u001b[0;31mValueError\u001b[0m: Target URI https://ml.googleapis.com/v1/projects/minist-microservice/models/mnist_model returns HTTP 404 error.\nPlease check if the project, model, and version names are given correctly."
     ]
    }
   ],
   "source": [
    "from explainable_ai_sdk import load_model_from_ai_platform\n",
    "\n",
    "# Load deployed model\n",
    "remote_model = load_model_from_ai_platform(\n",
    "    PROJECT_ID,\n",
    "    MODEL_NAME,\n",
    ")\n",
    "\n",
    "# Get explanations\n",
    "explanations = remote_model.explain(instances)\n",
    "\n",
    "# Visualize\n",
    "explanations[0].visualize_attributions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34b4d47-949c-428b-b03e-90078deba0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6df0be0-1424-4d74-a9ca-a7634417c19d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "efac4a63-00a4-4762-ba8f-46008e676451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b82a4fa-bee1-4cfc-89f6-85cc15fa02ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
